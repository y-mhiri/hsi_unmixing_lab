{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Exercise 4: Blind Hyperspectral Unmixing (Advanced)\n",
    "\n",
    "## Objectives\n",
    "- Understand the challenges of blind unmixing\n",
    "- Implement Block Coordinate Descent (BCD) algorithm\n",
    "- Analyze initialization strategies\n",
    "- Compare blind vs. supervised unmixing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import HyperspectralDataLoader, create_synthetic_data\n",
    "from visualization import HSIVisualizer\n",
    "from optimization import HyperspectralUnmixer, BlindUnmixer\n",
    "from metrics import UnmixingEvaluator, compute_endmember_similarity\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Understanding the Blind Unmixing Problem\n",
    "\n",
    "In blind unmixing, we must estimate both endmembers S and abundances A simultaneously:\n",
    "\n",
    "$$\\min_{\\mathbf{S}, \\mathbf{A}} \\|\\mathbf{S}\\mathbf{A} - \\mathbf{Y}\\|_F^2 \\quad \\text{s.t.} \\quad \\mathbf{A} \\geq 0, \\mathbf{1}^T\\mathbf{A} = \\mathbf{1}^T, \\mathbf{S} \\geq 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "loader = HyperspectralDataLoader(\"../data/\")\n",
    "hsi_data, ground_truth = loader.load_indian_pines()\n",
    "Y, _ = loader.vectorize_data()\n",
    "\n",
    "# Load known endmembers for comparison\n",
    "S_true = np.load('../data/extracted_endmembers.npy')\n",
    "endmember_names = np.load('../data/endmember_names.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Data shape: {Y.shape}\")\n",
    "print(f\"True endmembers shape: {S_true.shape}\")\n",
    "print(f\"Endmember names: {list(endmember_names)}\")\n",
    "\n",
    "# Analyze the challenge\n",
    "num_bands, num_pixels = Y.shape\n",
    "num_endmembers = S_true.shape[1]\n",
    "num_unknowns = num_bands * num_endmembers + num_endmembers * num_pixels\n",
    "num_observations = num_bands * num_pixels\n",
    "\n",
    "print(f\"\\nProblem Analysis:\")\n",
    "print(f\"  Number of observations: {num_observations}\")\n",
    "print(f\"  Number of unknowns: {num_unknowns}\")\n",
    "print(f\"  Problem is {'over' if num_observations > num_unknowns else 'under'}-determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement Block Coordinate Descent\n",
    "\n",
    "BCD alternates between optimizing S (with A fixed) and A (with S fixed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_coordinate_descent_manual(Y, num_endmembers, max_iter=50, \n",
    "                                  inner_max_iter=100, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Manual implementation of Block Coordinate Descent for blind unmixing.\n",
    "    \n",
    "    TODO: Implement the BCD algorithm\n",
    "    \"\"\"\n",
    "    bands, num_pixels = Y.shape\n",
    "    \n",
    "    # Initialize endmembers and abundances\n",
    "    # TODO: Initialize S with random normalized columns\n",
    "    S = # YOUR CODE HERE\n",
    "    \n",
    "    # TODO: Initialize A on the simplex\n",
    "    A = # YOUR CODE HERE\n",
    "    \n",
    "    unmixer = HyperspectralUnmixer()\n",
    "    objective_values = []\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        # Compute current objective\n",
    "        residual = S @ A - Y\n",
    "        objective = 0.5 * np.sum(residual**2)\n",
    "        objective_values.append(objective)\n",
    "        \n",
    "        print(f\"Iteration {iteration+1}/{max_iter}, Objective: {objective:.6f}\")\n",
    "        \n",
    "        # Step 1: Update A with S fixed (simplex-constrained least squares)\n",
    "        # TODO: Use the unmixer to solve the A subproblem\n",
    "        A, _ = # YOUR CODE HERE\n",
    "        \n",
    "        # Step 2: Update S with A fixed (non-negative least squares)\n",
    "        # This is equivalent to solving: min ||A^T S^T - Y^T||_F^2 s.t. S^T >= 0\n",
    "        # TODO: Use projected gradient for the S subproblem\n",
    "        S_new, _ = # YOUR CODE HERE (note the transpose!)\n",
    "        S = S_new.T\n",
    "        \n",
    "        # Normalize endmembers (optional, helps with scaling)\n",
    "        S = S / np.linalg.norm(S, axis=0)\n",
    "        \n",
    "        # Check convergence\n",
    "        if iteration > 0:\n",
    "            rel_change = abs(objective_values[-1] - objective_values[-2]) / objective_values[-2]\n",
    "            if rel_change < tolerance:\n",
    "                print(f\"Converged after {iteration+1} iterations\")\n",
    "                break\n",
    "    \n",
    "    return S, A, objective_values\n",
    "\n",
    "# Test with synthetic data first\n",
    "print(\"Testing BCD with synthetic data...\")\n",
    "hsi_synthetic, S_synth_true, A_synth_true = create_synthetic_data(\n",
    "    height=30, width=30, bands=50, num_endmembers=3, noise_level=0.02)\n",
    "\n",
    "Y_synth = hsi_synthetic.reshape(-1, hsi_synthetic.shape[2]).T\n",
    "\n",
    "# Apply BCD\n",
    "S_estimated, A_estimated, obj_values = block_coordinate_descent_manual(\n",
    "    Y_synth, num_endmembers=3, max_iter=20)\n",
    "\n",
    "print(f\"\\nSynthetic test completed in {len(obj_values)} iterations\")\n",
    "print(f\"Final objective: {obj_values[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluate Synthetic Results\n",
    "\n",
    "Compare estimated endmembers and abundances with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate endmember recovery\n",
    "endmember_similarity = compute_endmember_similarity(S_synth_true, S_estimated)\n",
    "\n",
    "print(\"Endmember Recovery Analysis:\")\n",
    "print(f\"  Mean SAM (degrees): {endmember_similarity['mean_endmember_sam_degrees']:.4f}\")\n",
    "print(f\"  Correlation: {endmember_similarity['endmember_correlation']:.4f}\")\n",
    "\n",
    "# TODO: Evaluate abundance recovery\n",
    "evaluator = UnmixingEvaluator()\n",
    "aad = evaluator.abundance_angle_distance(A_synth_true, A_estimated)\n",
    "print(f\"  Abundance AAD (degrees): {np.degrees(aad):.4f}\")\n",
    "\n",
    "# Visualize synthetic results\n",
    "visualizer = HSIVisualizer()\n",
    "\n",
    "# Plot true vs estimated endmembers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(3):\n",
    "    axes[0].plot(S_synth_true[:, i], label=f'True EM{i+1}', linewidth=2)\n",
    "    axes[1].plot(S_estimated[:, i], label=f'Est. EM{i+1}', linewidth=2)\n",
    "\n",
    "axes[0].set_title('True Endmembers')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_title('Estimated Endmembers')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot convergence\n",
    "visualizer.plot_convergence(obj_values, \"BCD Convergence (Synthetic Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Apply to Real Data\n",
    "\n",
    "Now apply blind unmixing to the Indian Pines dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply BCD to real data (use subset for faster computation)\n",
    "print(\"Applying BCD to Indian Pines data...\")\n",
    "\n",
    "# Use library implementation for efficiency\n",
    "unmixer = HyperspectralUnmixer()\n",
    "blind_unmixer = BlindUnmixer(unmixer)\n",
    "\n",
    "num_endmembers = S_true.shape[1]  # Same number as supervised case\n",
    "\n",
    "# Use subset of data for faster computation\n",
    "step = 3  # Use every 3rd pixel\n",
    "Y_subset = Y[:, ::step]\n",
    "print(f\"Using subset: {Y_subset.shape}\")\n",
    "\n",
    "# Run blind unmixing\n",
    "S_blind, A_blind_subset, obj_blind = blind_unmixer.block_coordinate_descent(\n",
    "    Y_subset, num_endmembers, max_iter=30, inner_max_iter=100)\n",
    "\n",
    "print(f\"\\nBlind unmixing completed in {len(obj_blind)} iterations\")\n",
    "print(f\"Final objective: {obj_blind[-1]:.6f}\")\n",
    "\n",
    "# Apply estimated endmembers to full dataset\n",
    "A_blind_full, _ = unmixer.fully_constrained_least_squares(S_blind, Y, max_iter=200)\n",
    "\n",
    "print(f\"Estimated endmembers shape: {S_blind.shape}\")\n",
    "print(f\"Full abundance matrix shape: {A_blind_full.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Compare Blind vs. Supervised Results\n",
    "\n",
    "Evaluate how blind unmixing compares to supervised unmixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load supervised results for comparison\n",
    "A_supervised = np.load('../data/simplex_abundances.npy')\n",
    "\n",
    "# Evaluate both methods\n",
    "height, width = hsi_data.shape[:2]\n",
    "rgb_bands = loader.get_rgb_bands()\n",
    "\n",
    "# Supervised results\n",
    "results_supervised = evaluator.evaluate_reconstruction(\n",
    "    S_true, A_supervised, Y, (height, width), rgb_bands)\n",
    "\n",
    "# Blind results\n",
    "results_blind = evaluator.evaluate_reconstruction(\n",
    "    S_blind, A_blind_full, Y, (height, width), rgb_bands)\n",
    "\n",
    "# Compare methods\n",
    "comparison = {\n",
    "    'Supervised': results_supervised,\n",
    "    'Blind': results_blind\n",
    "}\n",
    "\n",
    "evaluator.compare_methods(comparison)\n",
    "\n",
    "# Endmember similarity analysis\n",
    "endmember_sim = compute_endmember_similarity(S_true, S_blind)\n",
    "print(f\"\\nEndmember Recovery from Real Data:\")\n",
    "print(f\"  Mean SAM (degrees): {endmember_sim['mean_endmember_sam_degrees']:.4f}\")\n",
    "print(f\"  Correlation: {endmember_sim['endmember_correlation']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Visualization and Analysis\n",
    "\n",
    "Create comprehensive visualizations of blind unmixing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot endmember comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# True endmembers\n",
    "for i in range(S_true.shape[1]):\n",
    "    axes[0].plot(S_true[:, i], label=endmember_names[i], linewidth=2)\n",
    "axes[0].set_title('Supervised Endmembers (Ground Truth)')\n",
    "axes[0].set_xlabel('Band Index')\n",
    "axes[0].set_ylabel('Reflectance')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Estimated endmembers\n",
    "estimated_names = [f'Est. {name}' for name in endmember_names]\n",
    "for i in range(S_blind.shape[1]):\n",
    "    axes[1].plot(S_blind[:, i], label=estimated_names[i], linewidth=2)\n",
    "axes[1].set_title('Blind Unmixing Endmembers')\n",
    "axes[1].set_xlabel('Band Index')\n",
    "axes[1].set_ylabel('Reflectance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Plot abundance maps\n",
    "print(\"\\nBlind Unmixing Abundance Maps:\")\n",
    "visualizer.plot_abundance_maps(A_blind_full, (height, width), estimated_names)\n",
    "\n",
    "# TODO: Plot convergence\n",
    "visualizer.plot_convergence(obj_blind, \"Blind Unmixing Convergence (Real Data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Initialization Sensitivity Analysis\n",
    "\n",
    "Test how sensitive the algorithm is to different initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test multiple random initializations\n",
    "num_trials = 5\n",
    "initialization_results = []\n",
    "\n",
    "# Use smaller subset for multiple trials\n",
    "Y_small = Y[:, ::10]  # Every 10th pixel\n",
    "print(f\"Testing with {Y_small.shape[1]} pixels\")\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    print(f\"\\nTrial {trial+1}/{num_trials}\")\n",
    "    \n",
    "    # Set different random seed for each trial\n",
    "    np.random.seed(trial + 42)\n",
    "    \n",
    "    try:\n",
    "        S_trial, A_trial, obj_trial = blind_unmixer.block_coordinate_descent(\n",
    "            Y_small, num_endmembers, max_iter=20, initialization='random')\n",
    "        \n",
    "        # Evaluate trial\n",
    "        final_objective = obj_trial[-1]\n",
    "        convergence_rate = (obj_trial[0] - obj_trial[-1]) / obj_trial[0]\n",
    "        \n",
    "        # Endmember similarity (if possible to match order)\n",
    "        try:\n",
    "            endmember_sim = compute_endmember_similarity(S_true, S_trial)\n",
    "            mean_sam = endmember_sim['mean_endmember_sam_degrees']\n",
    "        except:\n",
    "            mean_sam = float('inf')\n",
    "        \n",
    "        initialization_results.append({\n",
    "            'trial': trial + 1,\n",
    "            'final_objective': final_objective,\n",
    "            'convergence_rate': convergence_rate,\n",
    "            'mean_sam': mean_sam,\n",
    "            'iterations': len(obj_trial)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Final objective: {final_objective:.6f}\")\n",
    "        print(f\"  Convergence rate: {convergence_rate:.4f}\")\n",
    "        print(f\"  Mean SAM: {mean_sam:.4f}°\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Trial {trial+1} failed: {e}\")\n",
    "\n",
    "# Analyze initialization sensitivity\n",
    "if initialization_results:\n",
    "    objectives = [r['final_objective'] for r in initialization_results]\n",
    "    sams = [r['mean_sam'] for r in initialization_results if r['mean_sam'] != float('inf')]\n",
    "    \n",
    "    print(f\"\\nInitialization Sensitivity Analysis:\")\n",
    "    print(f\"  Objective std: {np.std(objectives):.6f}\")\n",
    "    print(f\"  Best objective: {np.min(objectives):.6f}\")\n",
    "    print(f\"  Worst objective: {np.max(objectives):.6f}\")\n",
    "    \n",
    "    if sams:\n",
    "        print(f\"  SAM std: {np.std(sams):.4f}°\")\n",
    "        print(f\"  Best SAM: {np.min(sams):.4f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Algorithm Limitations Analysis\n",
    "\n",
    "Investigate the limitations and failure modes of blind unmixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test with different numbers of endmembers\n",
    "endmember_counts = [2, 3, 4, 5]\n",
    "count_results = {}\n",
    "\n",
    "for K in endmember_counts:\n",
    "    print(f\"\\nTesting with {K} endmembers...\")\n",
    "    \n",
    "    try:\n",
    "        S_K, A_K, obj_K = blind_unmixer.block_coordinate_descent(\n",
    "            Y_small, K, max_iter=15)\n",
    "        \n",
    "        # Evaluate reconstruction quality\n",
    "        reconstruction_error = np.mean((S_K @ A_K - Y_small)**2)\n",
    "        \n",
    "        count_results[K] = {\n",
    "            'final_objective': obj_K[-1],\n",
    "            'reconstruction_error': reconstruction_error,\n",
    "            'iterations': len(obj_K)\n",
    "        }\n",
    "        \n",
    "        print(f\"  Final objective: {obj_K[-1]:.6f}\")\n",
    "        print(f\"  Reconstruction error: {reconstruction_error:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Failed with {K} endmembers: {e}\")\n",
    "\n",
    "# Plot results\n",
    "if count_results:\n",
    "    counts = list(count_results.keys())\n",
    "    objectives = [count_results[k]['final_objective'] for k in counts]\n",
    "    errors = [count_results[k]['reconstruction_error'] for k in counts]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(counts, objectives, 'bo-', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Number of Endmembers')\n",
    "    axes[0].set_ylabel('Final Objective')\n",
    "    axes[0].set_title('Objective vs. Number of Endmembers')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(counts, errors, 'ro-', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Number of Endmembers')\n",
    "    axes[1].set_ylabel('Reconstruction Error')\n",
    "    axes[1].set_title('Error vs. Number of Endmembers')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze identifiability issues\n",
    "print(f\"\\nIdentifiability Analysis:\")\n",
    "print(f\"  True number of endmembers: {S_true.shape[1]}\")\n",
    "print(f\"  Recommended: Use prior knowledge when possible\")\n",
    "print(f\"  Challenge: Local minima depend on initialization\")\n",
    "print(f\"  Solution: Multiple runs with different initializations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. **What are the main challenges of blind unmixing compared to supervised unmixing?**\n",
    "\n",
    "   *Your answer here*\n",
    "\n",
    "2. **How does initialization affect the final result? Why?**\n",
    "\n",
    "   *Your answer here*\n",
    "\n",
    "3. **What role does the number of endmembers play in algorithm performance?**\n",
    "\n",
    "   *Your answer here*\n",
    "\n",
    "4. **Under what conditions might blind unmixing be preferred over supervised methods?**\n",
    "\n",
    "   *Your answer here*\n",
    "\n",
    "5. **How could you improve the robustness of blind unmixing algorithms?**\n",
    "\n",
    "   *Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "Based on this exercise, here are key takeaways for blind unmixing:\n",
    "\n",
    "1. **Initialization matters**: Run multiple trials with different random seeds\n",
    "2. **Convergence monitoring**: Always plot objective function evolution\n",
    "3. **Parameter tuning**: Adjust step sizes and iteration counts based on data\n",
    "4. **Validation**: Compare with known methods when possible\n",
    "5. **Regularization**: Consider adding constraints or penalties for better solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON: SUPERVISED vs BLIND UNMIXING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Supervised (SAM): {results_supervised['mean_sam_degrees']:.4f}°\")\n",
    "print(f\"Blind (SAM):      {results_blind['mean_sam_degrees']:.4f}°\")\n",
    "print(f\"Supervised (RMSE): {results_supervised['rmse']:.6f}\")\n",
    "print(f\"Blind (RMSE):      {results_blind['rmse']:.6f}\")\n",
    "\n",
    "performance_ratio = results_blind['mean_sam_degrees'] / results_supervised['mean_sam_degrees']\n",
    "print(f\"\\nBlind/Supervised performance ratio: {performance_ratio:.2f}\")\n",
    "\n",
    "if performance_ratio < 2.0:\n",
    "    print(\"✓ Blind unmixing achieved reasonable performance!\")\n",
    "else:\n",
    "    print(\"⚠ Blind unmixing significantly worse - try different parameters\")\n",
    "\n",
    "print(\"\\nLab Exercise 4 completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
